{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f28688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import imageio\n",
    "from scipy.optimize import minimize\n",
    "from joblib import Parallel, delayed\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3de73535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded fixed arbitrary graph with 50 nodes and 532 edges and 21.28 average degree.\n"
     ]
    }
   ],
   "source": [
    "#Initialize parameters\n",
    "N = 50 #Number of nodes\n",
    "l = 3  # Number of topics\n",
    "lambda_val = 0.5 #Decay parameter \n",
    "\n",
    "# Rebuild A_initial from graph metadata saved\n",
    "A_initial = np.array([G.nodes[n]['initial_opinion'] for n in G.nodes])\n",
    "\n",
    "# Load static arbitrary graph\n",
    "with open(\"fixed_graph_arbitrary.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded fixed arbitrary graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges and {np.mean([d for _, d in G.degree()])} average degree.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe3c0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Player Class and Simulation\n",
    "class Player:\n",
    "    def __init__(self, theta_low, theta_high, delta, beta, topic_index, agent_id, push_toward, l, kappa, gamma):\n",
    "        self.theta_low = theta_low\n",
    "        self.theta_high = theta_high\n",
    "        self.delta = delta\n",
    "        self.beta = beta\n",
    "        self.topic_index = topic_index\n",
    "        self.agent_id = agent_id\n",
    "        self.push_toward = push_toward\n",
    "        self.l = l\n",
    "        self.kappa = kappa\n",
    "        self.gamma = gamma\n",
    "   \n",
    "    #Link weight calculation\n",
    "    def compute_w_link(self, A_updated):\n",
    "        N = A_updated.shape[0]\n",
    "        w_link_matrix = np.zeros((N, N))\n",
    "        for i in range(N):\n",
    "            for j in range(i + 1, N):\n",
    "                distance = np.linalg.norm(A_updated[i] - A_updated[j])\n",
    "                w_link_matrix[i, j] = np.exp(-distance)\n",
    "                w_link_matrix[j, i] = w_link_matrix[i, j]\n",
    "        return w_link_matrix\n",
    "    \n",
    "    #Simulating for intial node\n",
    "    def send_message_single_agent(self, network, initial_node, message):\n",
    "        active_nodes = set()\n",
    "        claimed_nodes = {}\n",
    "        A_updated = np.copy(A_initial)\n",
    "\n",
    "        alignment = self.beta * (1 - np.linalg.norm(A_initial[initial_node] - message) / (2 * np.sqrt(self.l)))\n",
    "\n",
    "        if alignment > self.theta_low:\n",
    "            w_link_matrix = self.compute_w_link(A_updated)\n",
    "            neighbors = list(network.neighbors(initial_node))\n",
    "            Z_i = np.sum(w_link_matrix[initial_node, neighbors])\n",
    "            neighbor_influence = np.sum([A_updated[j] * w_link_matrix[initial_node, j] for j in neighbors]) / Z_i if Z_i > 0 else 0  \n",
    "            A_updated[initial_node] = (1 - self.kappa - self.gamma) * A_updated[initial_node] + self.kappa * message + self.gamma * neighbor_influence\n",
    "            active_nodes.add(initial_node)\n",
    "            claimed_nodes[initial_node] = self.agent_id\n",
    "\n",
    "        timestep_count = 0\n",
    "        while True:\n",
    "            new_active_nodes = set()\n",
    "            w_link_matrix = self.compute_w_link(A_updated)\n",
    "            for node in active_nodes:\n",
    "                for neighbor in network.neighbors(node):\n",
    "                    if neighbor in claimed_nodes:\n",
    "                        continue\n",
    "                    if w_link_matrix[node, neighbor] > self.delta:\n",
    "                        alignment = self.beta * (1 - np.linalg.norm(A_updated[neighbor] - message) / (2 * np.sqrt(self.l)))\n",
    "                        if alignment > self.theta_low:\n",
    "                            neighbors = list(network.neighbors(node))\n",
    "                            Z_i = np.sum(w_link_matrix[node, neighbors])\n",
    "                            neighbor_influence = np.sum([A_updated[j] * w_link_matrix[node, j] for j in neighbors]) / Z_i if Z_i > 0 else 0\n",
    "                            A_updated[neighbor] = (1 - self.kappa - self.gamma) * A_updated[neighbor] + self.kappa * message + self.gamma * neighbor_influence\n",
    "                            new_active_nodes.add(neighbor)\n",
    "                            claimed_nodes[neighbor] = self.agent_id\n",
    "            if not new_active_nodes:\n",
    "                break\n",
    "            active_nodes.update(new_active_nodes)\n",
    "            timestep_count += 1\n",
    "        #Adjusting influence for negative direction\n",
    "        total_influence = self.push_toward*np.sum(A_updated[:, self.topic_index] - A_initial[:, self.topic_index])\n",
    "        return total_influence, A_updated, claimed_nodes, timestep_count\n",
    "\n",
    "\n",
    "    #Optimizing using base vectors over all nodes\n",
    "    def optimize_strategy_single_agent(self, network, n_jobs=-1):\n",
    "        #Base vectors\n",
    "        base_vectors = [np.eye(self.l)[i] for i in range(self.l)] + [-np.eye(self.l)[i] for i in range(self.l)]\n",
    "        sampled_messages = base_vectors + [np.random.uniform(-1, 1, self.l) for _ in range(3)]\n",
    "\n",
    "        def evaluate_strategy(initial_node, message):\n",
    "            influence, _, _, _ = self.send_message_single_agent(network, initial_node, message)\n",
    "            return (initial_node, message, influence)\n",
    "\n",
    "        all_jobs = [(node, message) for node in network.nodes for message in sampled_messages]\n",
    "\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(evaluate_strategy)(node, msg) for node, msg in all_jobs\n",
    "        )\n",
    "\n",
    "        #Find optimal choice\n",
    "        best_node, best_message, max_influence = max(results, key=lambda x: x[2])\n",
    "\n",
    "        return best_node, best_message, max_influence\n",
    "\n",
    "#Simulating diffusion t>=2\n",
    "def simulate_diffusion(player, network, initial_node, message):\n",
    "    active_nodes_history = []\n",
    "    A_updated = np.copy(A_initial)\n",
    "    active_nodes = set([initial_node])\n",
    "    claimed_nodes = {initial_node: player.agent_id}\n",
    "    active_nodes_history.append(set(active_nodes))\n",
    "\n",
    "    influence_history = []\n",
    "    #Simulate until influence can no longer spread\n",
    "    while True:\n",
    "        new_active_nodes = set()\n",
    "        w_link_matrix = player.compute_w_link(A_updated)\n",
    "        for node in active_nodes:\n",
    "            for neighbor in network.neighbors(node):\n",
    "                if neighbor in claimed_nodes:\n",
    "                    continue\n",
    "                if w_link_matrix[node, neighbor] > player.delta:\n",
    "                    alignment = player.beta * (1 - np.linalg.norm(A_updated[neighbor] - message) / (2 * np.sqrt(player.l)))\n",
    "                    if alignment > player.theta_low:\n",
    "                        neighbors = list(network.neighbors(node))\n",
    "                        Z_i = np.sum(w_link_matrix[node, neighbors])\n",
    "                        neighbor_influence = np.sum([A_updated[j] * w_link_matrix[node, j] for j in neighbors]) / Z_i if Z_i > 0 else 0\n",
    "                        A_updated[neighbor] = (1 - player.kappa - player.gamma) * A_updated[neighbor] + player.kappa * message + player.gamma * neighbor_influence\n",
    "                        new_active_nodes.add(neighbor)\n",
    "                        claimed_nodes[neighbor] = player.agent_id\n",
    "        if not new_active_nodes:\n",
    "            break\n",
    "        active_nodes.update(new_active_nodes)\n",
    "        active_nodes_history.append(set(active_nodes))\n",
    "        #Adjusting influence for negative direction\n",
    "        influence_t = player.push_toward*np.sum(A_updated[:, player.topic_index] - A_initial[:, player.topic_index])\n",
    "        influence_history.append(influence_t)\n",
    "\n",
    "    return active_nodes_history, A_updated, claimed_nodes, influence_history\n",
    "\n",
    "#Visualizing network diffusion\n",
    "def visualize_single_agent_diffusion(G, active_nodes_history, A_updated, claimed_nodes, topic_index, message):\n",
    "    topic_names = {0: \"Affirmative Action\", 1: \"Gun Permits\", 2: \"Political Party ID\"}\n",
    "    topic_name = topic_names.get(topic_index, \"Unknown Topic\")\n",
    "    max_timesteps = len(active_nodes_history)\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "    for t in range(max_timesteps):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        node_colors = []\n",
    "        current_claimed = set()\n",
    "        for i in range(t + 1):\n",
    "            current_claimed.update(active_nodes_history[i])\n",
    "        for n in G.nodes():\n",
    "            node_colors.append(\"red\" if n in current_claimed else \"gray\")\n",
    "        nx.draw(G, pos, with_labels=False, node_color=node_colors, node_size=50, edge_color=\"lightgray\")\n",
    "        plt.title(f\"{topic_name} – Agent Influence at Step {t+1}\")\n",
    "        filename = os.path.join(\"[INSERT DIRECTORY]\", f\"{topic_name} – Agent(-1) Influence at Step {t+1}.png\")\n",
    "\n",
    "        plt.savefig(filename, dpi=300)\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af80d665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Metrics (First 5 Rows):\n",
      "   Node  Degree  Clustering Coefficient  Degree Centrality  \\\n",
      "0     0       3                0.333333           0.333333   \n",
      "1     1       3                0.666667           0.333333   \n",
      "2     2       3                0.333333           0.333333   \n",
      "3     3       4                0.666667           0.444444   \n",
      "4     4       3                0.666667           0.333333   \n",
      "\n",
      "   Betweenness Centrality  \n",
      "0                0.030093  \n",
      "1                0.030093  \n",
      "2                0.023148  \n",
      "3                0.023148  \n",
      "4                0.030093  \n"
     ]
    }
   ],
   "source": [
    "#Computing clustering coefficient and centrality measures\n",
    "clustering_coeffs = nx.clustering(G)\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "\n",
    "#Converting centrality and clustering metrics to a frame for analysis\n",
    "network_metrics = pd.DataFrame({\n",
    "    \"Node\": list(G.nodes()),\n",
    "    \"Degree\": [G.degree(n) for n in G.nodes()],\n",
    "    \"Clustering Coefficient\": [clustering_coeffs[n] for n in G.nodes()],\n",
    "    \"Degree Centrality\": [degree_centrality[n] for n in G.nodes()],\n",
    "    \"Betweenness Centrality\": [betweenness_centrality[n] for n in G.nodes()]\n",
    "})\n",
    "\n",
    "\n",
    "#Display network metrics\n",
    "print(\"Network Metrics (First 5 Rows):\")\n",
    "print(network_metrics.head())\n",
    "\n",
    "#Saving network metrics to a CSV file \n",
    "network_metrics.to_csv(\"[INSERT DIRECTORY]/1Pnetwork_metricsparalleltoNEG1arbitrary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df405a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to run parallel simulations\n",
    "def run_single_simulation(sim_idx, topic_index, push_toward, G, A_initial, l, player_config):\n",
    "    player = Player(\n",
    "        theta_low=player_config[\"theta_low\"],\n",
    "        theta_high=player_config[\"theta_high\"],\n",
    "        delta=player_config[\"delta\"],\n",
    "        beta=player_config[\"beta\"],\n",
    "        topic_index=topic_index,\n",
    "        agent_id=1,\n",
    "        push_toward=push_toward,\n",
    "        l=l,\n",
    "        kappa=player_config[\"kappa\"],\n",
    "        gamma=player_config[\"gamma\"]\n",
    "    )\n",
    "    try:\n",
    "        optimal_node, optimal_message, max_influence = player.optimize_strategy_single_agent(G)\n",
    "        _, _, claimed_nodes, influence_history = simulate_diffusion(player, G, optimal_node, optimal_message)\n",
    "        return {\n",
    "            \"Simulation\": sim_idx,\n",
    "            \"Topic\": topic_index,\n",
    "            \"Push Direction\": push_toward,\n",
    "            \"Initial Node\": optimal_node,\n",
    "            \"Optimal Message\": optimal_message,\n",
    "            \"Total Influence\": max_influence,\n",
    "            \"Steps\": len(influence_history)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Simulation {sim_idx} Topic {topic_index} failed: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7cdbd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to parallel_simulation_resultsArbitrarytoNEG1.csv\n"
     ]
    }
   ],
   "source": [
    "#Initailizations for simulations\n",
    "N_SIMULATIONS = 50\n",
    "TOPICS = [0, 1, 2]\n",
    "PUSH = -1  \n",
    "n_jobs = -1  #available CPU cores\n",
    "\n",
    "# Define shared config\n",
    "player_config = {\n",
    "    \"theta_low\": 0.3,\n",
    "    \"theta_high\": 0.7,\n",
    "    \"delta\": 0.625,\n",
    "    \"beta\": 1,\n",
    "    \"kappa\": 0.3,\n",
    "    \"gamma\": 0.2\n",
    "}\n",
    "\n",
    "#Using parallel processing--> create job list\n",
    "job_list = [(sim, topic, PUSH, G, A_initial, l, player_config)\n",
    "            for sim in range(N_SIMULATIONS) for topic in TOPICS]\n",
    "\n",
    "#Run in parallel\n",
    "results = Parallel(n_jobs=n_jobs)(\n",
    "    delayed(run_single_simulation)(*job) for job in job_list\n",
    ")\n",
    "\n",
    "#Filter for failed runs\n",
    "results_clean = [r for r in results if r is not None]\n",
    "\n",
    "#Save to DataFrame\n",
    "df_results = pd.DataFrame(results_clean)\n",
    "df_results.to_csv(\"/[INSERT DIRECTORY]/parallel_simulation_resultsArbitrarytoNEG1.csv\", index=False)\n",
    "print(\"Saved results to parallel_simulation_resultsArbitrarytoNEG1.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
