{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f28688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>yearid</th>\n",
       "      <th>year_1b</th>\n",
       "      <th>year_2</th>\n",
       "      <th>id_1b</th>\n",
       "      <th>id_2</th>\n",
       "      <th>coninc_1b</th>\n",
       "      <th>coninc_2</th>\n",
       "      <th>race_1b</th>\n",
       "      <th>sexnow_1b</th>\n",
       "      <th>sexnow1_2</th>\n",
       "      <th>affrmact_norm1b</th>\n",
       "      <th>gunlaw_norm1b</th>\n",
       "      <th>partyid_norm1b</th>\n",
       "      <th>affrmact_norm2</th>\n",
       "      <th>gunlaw_norm2</th>\n",
       "      <th>partyid_norm2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20180001</td>\n",
       "      <td>2018</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36960.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20180006</td>\n",
       "      <td>2018</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20180011</td>\n",
       "      <td>2018</td>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>819</td>\n",
       "      <td>112160.0</td>\n",
       "      <td>94080.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20180016</td>\n",
       "      <td>2018</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "      <td>822</td>\n",
       "      <td>47317.5</td>\n",
       "      <td>15960.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20180063</td>\n",
       "      <td>2018</td>\n",
       "      <td>2020</td>\n",
       "      <td>63</td>\n",
       "      <td>836</td>\n",
       "      <td>38555.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    yearid  year_1b  year_2  id_1b  id_2  coninc_1b  coninc_2  \\\n",
       "0           1  20180001     2018    2020      1   810        NaN   36960.0   \n",
       "1           2  20180006     2018    2020      6   815        NaN   25200.0   \n",
       "2           3  20180011     2018    2020     11   819   112160.0   94080.0   \n",
       "3           4  20180016     2018    2020     16   822    47317.5   15960.0   \n",
       "4           5  20180063     2018    2020     63   836    38555.0       NaN   \n",
       "\n",
       "   race_1b  sexnow_1b  sexnow1_2  affrmact_norm1b  gunlaw_norm1b  \\\n",
       "0        1        NaN          1        -1.000000              1   \n",
       "1        1        NaN          2         0.333333              1   \n",
       "2        1        NaN          1        -1.000000              1   \n",
       "3        1        NaN          2        -0.333333              1   \n",
       "4        2        NaN          2         0.333333              1   \n",
       "\n",
       "   partyid_norm1b  affrmact_norm2  gunlaw_norm2  partyid_norm2  \n",
       "0       -0.666667       -1.000000           1.0      -1.000000  \n",
       "1        0.333333       -0.333333           1.0       0.333333  \n",
       "2       -1.000000       -1.000000           1.0      -1.000000  \n",
       "3        0.000000       -1.000000           1.0       0.000000  \n",
       "4        1.000000        1.000000           1.0       1.000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import imageio\n",
    "from scipy.optimize import minimize\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "\n",
    "df = pd.read_csv(\"df_normalizedcleanfinalscaled.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c3adb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded fixed graph with 281 nodes and 14191 edges\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load static graph from file\n",
    "with open(\"fixed_graph.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "# Visualize or verify structure\n",
    "print(f\"Loaded fixed graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "\n",
    "opinion_cols_1b = [\"affrmact_norm1b\", \"gunlaw_norm1b\", \"partyid_norm1b\"]\n",
    "opinion_cols_2 = [\"affrmact_norm2\", \"gunlaw_norm2\", \"partyid_norm2\"]\n",
    "# Clean the dataset\n",
    "df_clean = df.dropna(subset=opinion_cols_1b+opinion_cols_2)\n",
    "#Populate intial opinions frmo data\n",
    "A_initial = df_clean[opinion_cols_1b].values\n",
    "A_final = df_clean[opinion_cols_2].values\n",
    "N = A_initial.shape[0]\n",
    "l = A_initial.shape[1]\n",
    "lambda_val = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceca8a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Metrics (First 5 Rows):\n",
      "   Node  Degree  Clustering Coefficient  Degree Centrality  \\\n",
      "0     0     120                0.586695           0.427046   \n",
      "1     1     127                0.523060           0.451957   \n",
      "2     2      92                0.544673           0.327402   \n",
      "3     3     138                0.524807           0.491103   \n",
      "4     4     115                0.543555           0.409253   \n",
      "\n",
      "   Betweenness Centrality  \n",
      "0                0.002565  \n",
      "1                0.003350  \n",
      "2                0.001986  \n",
      "3                0.004589  \n",
      "4                0.002662  \n",
      "\n",
      "Average Connection Probability Per Topic:\n",
      "                    Avg Probability\n",
      "affirmative_action         0.731862\n",
      "gun_laws                   0.670030\n",
      "party_id                   0.719685\n"
     ]
    }
   ],
   "source": [
    "#computing clustering coefficient and centrality measures\n",
    "clustering_coeffs = nx.clustering(G)\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "\n",
    "#converting to a frame for analysis\n",
    "network_metrics = pd.DataFrame({\n",
    "    \"Node\": list(G.nodes()),\n",
    "    \"Degree\": [G.degree(n) for n in G.nodes()],\n",
    "    \"Clustering Coefficient\": [clustering_coeffs[n] for n in G.nodes()],\n",
    "    \"Degree Centrality\": [degree_centrality[n] for n in G.nodes()],\n",
    "    \"Betweenness Centrality\": [betweenness_centrality[n] for n in G.nodes()]\n",
    "})\n",
    "\n",
    "#compute average clustering based on topic alignment\n",
    "topic_similarity = {\"affirmative_action\": [], \"gun_laws\": [], \"party_id\": []}\n",
    "\n",
    "for i in range(N):\n",
    "    for j in range(i + 1, N):\n",
    "        distance = np.linalg.norm(A_initial[i] - A_initial[j])**2\n",
    "        probability = np.exp(- (1 /(4*lambda_val))*distance) #prob connected\n",
    "        \n",
    "        #separate contributions from each topic dimension\n",
    "        for idx, topic in enumerate([\"affirmative_action\", \"gun_laws\", \"party_id\"]):\n",
    "            topic_distance = (A_initial[i, idx] - A_initial[j, idx])**2\n",
    "            topic_prob = np.exp(- (1 / (4*lambda_val)) * topic_distance)\n",
    "            topic_similarity[topic].append(topic_prob)\n",
    "\n",
    "#computing average connection probability per topic\n",
    "average_topic_similarity = {topic: np.mean(values) for topic, values in topic_similarity.items()}\n",
    "\n",
    "\n",
    "#saving network metrics to a csv file \n",
    "network_metrics.to_csv(\"[INSERT DIRECTORY]/1Pnetwork_metricsparallelto-1.csv\", index=False)\n",
    "df_topic_similarity = pd.DataFrame.from_dict(average_topic_similarity, orient=\"index\", columns=[\"Avg Probability\"])\n",
    "df_topic_similarity.to_csv(\"/[INSERT DIRECTORY]/1Ptopic_similarityparallelto-1.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff3be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covariance/interdependance matrix\n",
    "topics2018 = opinion_cols_1b\n",
    "topics2020 = opinion_cols_2\n",
    "df_change = df_clean[topics2020].values - df_clean[topics2018].values\n",
    "C_covar = np.cov(df_change, rowvar=False)\n",
    "C_df = pd.DataFrame(C_covar, index=topics2018, columns=topics2018)\n",
    "C_stochastic = C_df.div(C_df.sum(axis=1), axis=0).clip(lower=0)\n",
    "C_stochastic = C_stochastic.div(C_stochastic.sum(axis=1), axis=0).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3c0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Player Class and Simulation \n",
    "class Player:\n",
    "    def __init__(self, theta_low, theta_high, delta, beta, topic_index, agent_id, push_toward, l, kappa, gamma):\n",
    "        self.theta_low = theta_low\n",
    "        self.theta_high = theta_high\n",
    "        self.delta = delta\n",
    "        self.beta = beta\n",
    "        self.topic_index = topic_index\n",
    "        self.agent_id = agent_id\n",
    "        self.push_toward = push_toward\n",
    "        self.l = l\n",
    "        self.kappa = kappa\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def compute_w_link(self, A_updated):\n",
    "        N = A_updated.shape[0]\n",
    "        w_link_matrix = np.zeros((N, N))\n",
    "        for i in range(N):\n",
    "            for j in range(i + 1, N):\n",
    "                distance = np.linalg.norm(A_updated[i] - A_updated[j])\n",
    "                w_link_matrix[i, j] = np.exp(-distance)\n",
    "                w_link_matrix[j, i] = w_link_matrix[i, j]\n",
    "        return w_link_matrix\n",
    "\n",
    "    def send_message_single_agent(self, network, initial_node, message, C):\n",
    "        active_nodes = set()\n",
    "        claimed_nodes = {}\n",
    "        A_updated = np.copy(A_initial)\n",
    "\n",
    "        alignment = self.beta * (1 - np.linalg.norm(A_initial[initial_node] - message) / (2 * np.sqrt(self.l)))\n",
    "\n",
    "        if alignment > self.theta_low:\n",
    "            w_link_matrix = self.compute_w_link(A_updated)\n",
    "            neighbors = list(network.neighbors(initial_node))\n",
    "            Z_i = np.sum(w_link_matrix[initial_node, neighbors])\n",
    "            neighbor_influence = np.sum([A_updated[j] * w_link_matrix[initial_node, j] for j in neighbors]) / Z_i if Z_i > 0 else 0  \n",
    "            A_updated[initial_node] = (1 - self.kappa - self.gamma) * A_updated[initial_node] + self.kappa * (C @ message) + self.gamma * neighbor_influence\n",
    "            active_nodes.add(initial_node)\n",
    "            claimed_nodes[initial_node] = self.agent_id\n",
    "\n",
    "        timestep_count = 0\n",
    "        while True:\n",
    "            new_active_nodes = set()\n",
    "            w_link_matrix = self.compute_w_link(A_updated)\n",
    "            for node in active_nodes:\n",
    "                for neighbor in network.neighbors(node):\n",
    "                    if neighbor in claimed_nodes:\n",
    "                        continue\n",
    "                    if w_link_matrix[node, neighbor] > self.delta:\n",
    "                        alignment = self.beta * (1 - np.linalg.norm(A_updated[neighbor] - message) / (2 * np.sqrt(self.l)))\n",
    "                        if alignment > self.theta_low:\n",
    "                            neighbors = list(network.neighbors(node))\n",
    "                            Z_i = np.sum(w_link_matrix[node, neighbors])\n",
    "                            neighbor_influence = np.sum([A_updated[j] * w_link_matrix[node, j] for j in neighbors]) / Z_i if Z_i > 0 else 0\n",
    "                            A_updated[neighbor] = (1 - self.kappa - self.gamma) * A_updated[neighbor] + self.kappa * (C @ message) + self.gamma * neighbor_influence\n",
    "                            new_active_nodes.add(neighbor)\n",
    "                            claimed_nodes[neighbor] = self.agent_id\n",
    "            if not new_active_nodes:\n",
    "                break\n",
    "            active_nodes.update(new_active_nodes)\n",
    "            timestep_count += 1\n",
    "        #fixing influence\n",
    "        total_influence = self.push_toward*np.sum(A_updated[:, self.topic_index] - A_initial[:, self.topic_index])\n",
    "        return total_influence, A_updated, claimed_nodes, timestep_count\n",
    "\n",
    "\n",
    "\n",
    "    def optimize_strategy_single_agent(self, network, C, n_jobs=-1):\n",
    "        base_vectors = [np.eye(self.l)[i] for i in range(self.l)] + [-np.eye(self.l)[i] for i in range(self.l)]\n",
    "        sampled_messages = base_vectors + [np.random.uniform(-1, 1, self.l) for _ in range(3)]\n",
    "\n",
    "        def evaluate_strategy(initial_node, message):\n",
    "            influence, _, _, _ = self.send_message_single_agent(network, initial_node, message, C)\n",
    "            return (initial_node, message, influence)\n",
    "\n",
    "        all_jobs = [(node, message) for node in network.nodes for message in sampled_messages]\n",
    "\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(evaluate_strategy)(node, msg) for node, msg in all_jobs\n",
    "        )\n",
    "\n",
    "        #optimizing for best \n",
    "        best_node, best_message, max_influence = max(results, key=lambda x: x[2])\n",
    "\n",
    "        return best_node, best_message, max_influence\n",
    "\n",
    "\n",
    "def simulate_diffusion(player, network, initial_node, message, C):\n",
    "    active_nodes_history = []\n",
    "    A_updated = np.copy(A_initial)\n",
    "    active_nodes = set([initial_node])\n",
    "    claimed_nodes = {initial_node: player.agent_id}\n",
    "    active_nodes_history.append(set(active_nodes))\n",
    "\n",
    "    influence_history = []\n",
    "    while True:\n",
    "        new_active_nodes = set()\n",
    "        w_link_matrix = player.compute_w_link(A_updated)\n",
    "        for node in active_nodes:\n",
    "            for neighbor in network.neighbors(node):\n",
    "                if neighbor in claimed_nodes:\n",
    "                    continue\n",
    "                if w_link_matrix[node, neighbor] > player.delta:\n",
    "                    alignment = player.beta * (1 - np.linalg.norm(A_updated[neighbor] - message) / (2 * np.sqrt(player.l)))\n",
    "                    if alignment > player.theta_low:\n",
    "                        neighbors = list(network.neighbors(node))\n",
    "                        Z_i = np.sum(w_link_matrix[node, neighbors])\n",
    "                        neighbor_influence = np.sum([A_updated[j] * w_link_matrix[node, j] for j in neighbors]) / Z_i if Z_i > 0 else 0\n",
    "                        A_updated[neighbor] = (1 - player.kappa - player.gamma) * A_updated[neighbor] + player.kappa * (C @ message) + player.gamma * neighbor_influence\n",
    "                        new_active_nodes.add(neighbor)\n",
    "                        claimed_nodes[neighbor] = player.agent_id\n",
    "        if not new_active_nodes:\n",
    "            break\n",
    "        active_nodes.update(new_active_nodes)\n",
    "        active_nodes_history.append(set(active_nodes))\n",
    "        #fixing influence\n",
    "        influence_t = player.push_toward*np.sum(A_updated[:, player.topic_index] - A_initial[:, player.topic_index])\n",
    "        influence_history.append(influence_t)\n",
    "\n",
    "    return active_nodes_history, A_updated, claimed_nodes, influence_history\n",
    "\n",
    "\n",
    "def visualize_single_agent_diffusion(G, active_nodes_history, A_updated, claimed_nodes, topic_index, message):\n",
    "    topic_names = {0: \"Affirmative Action\", 1: \"Gun Permits\", 2: \"Political Party ID\"}\n",
    "    topic_name = topic_names.get(topic_index, \"Unknown Topic\")\n",
    "    max_timesteps = len(active_nodes_history)\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "    for t in range(max_timesteps):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        node_colors = []\n",
    "        current_claimed = set()\n",
    "        for i in range(t + 1):\n",
    "            current_claimed.update(active_nodes_history[i])\n",
    "        for n in G.nodes():\n",
    "            node_colors.append(\"red\" if n in current_claimed else \"gray\")\n",
    "        nx.draw(G, pos, with_labels=False, node_color=node_colors, node_size=50, edge_color=\"lightgray\")\n",
    "        plt.title(f\"{topic_name} – Agent Influence at Step {t+1}\")\n",
    "        filename = os.path.join(\"/scratch/network/re0578/sameG/1Player/to-1/networkdiffusion\", f\"{topic_name} – Agent(-1) Influence at Step {t+1}.png\")\n",
    "\n",
    "        plt.savefig(filename, dpi=300)\n",
    "        plt.close()\n",
    "        #plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df405a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_simulation(sim_idx, topic_index, push_toward, G, C, A_initial, l, player_config):\n",
    "    player = Player(\n",
    "        theta_low=player_config[\"theta_low\"],\n",
    "        theta_high=player_config[\"theta_high\"],\n",
    "        delta=player_config[\"delta\"],\n",
    "        beta=player_config[\"beta\"],\n",
    "        topic_index=topic_index,\n",
    "        agent_id=1,\n",
    "        push_toward=push_toward,\n",
    "        l=l,\n",
    "        kappa=player_config[\"kappa\"],\n",
    "        gamma=player_config[\"gamma\"]\n",
    "    )\n",
    "    try:\n",
    "        optimal_node, optimal_message, max_influence = player.optimize_strategy_single_agent(G, C)\n",
    "        _, A_updated, claimed_nodes, influence_history = simulate_diffusion(player, G, optimal_node, optimal_message, C)\n",
    "        return {\n",
    "            \"Simulation\": sim_idx,\n",
    "            \"Topic\": topic_index,\n",
    "            \"Push Direction\": push_toward,\n",
    "            \"Initial Node\": optimal_node,\n",
    "            \"Optimal Message\": optimal_message,\n",
    "            \"Total Influence\": max_influence,\n",
    "            \"Steps\": len(influence_history),\n",
    "            \"Updated Opinons\": A_updated\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Simulation {sim_idx} Topic {topic_index} failed: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7cdbd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to monteto-1.csv\n"
     ]
    }
   ],
   "source": [
    "#intialization for Simulations\n",
    "N_SIMULATIONS = 50\n",
    "TOPICS = [0, 1, 2]\n",
    "PUSH = -1  \n",
    "n_jobs = -1  #all available CPU cores\n",
    "\n",
    "# Define shared config\n",
    "player_config = {\n",
    "    \"theta_low\": 0.3,\n",
    "    \"theta_high\": 0.7,\n",
    "    \"delta\": 0.4,\n",
    "    \"beta\": 1,\n",
    "    \"kappa\": 0.3,\n",
    "    \"gamma\": 0.2\n",
    "}\n",
    "\n",
    "#job list for parallel processing\n",
    "job_list = [(sim, topic, PUSH, G, C_stochastic, A_initial, l, player_config)\n",
    "            for sim in range(N_SIMULATIONS) for topic in TOPICS]\n",
    "\n",
    "#Run in parallel\n",
    "results = Parallel(n_jobs=n_jobs)(\n",
    "    delayed(run_single_simulation)(*job) for job in job_list\n",
    ")\n",
    "\n",
    "#Filter for failed runs\n",
    "results_clean = [r for r in results if r is not None]\n",
    "\n",
    "# ave to DataFrame\n",
    "df_results = pd.DataFrame(results_clean)\n",
    "df_results.to_csv(\"[DIRECTORY]/parallel_simulation_resultsParallelto-1.csv\", index=False)\n",
    "print(\"Saved results to parallel_simulation_resultsParallelto-1.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
